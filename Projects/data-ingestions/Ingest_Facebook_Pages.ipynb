{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b48f8d26-3306-4f17-b912-d91e5024fb8f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Utils/Functions/core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5615052e-ce10-403a-875e-d8aea7d17ed5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import concurrent.futures\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "from time import sleep, mktime\n",
    "from uuid import uuid4\n",
    "import json\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f328b2a0-af03-4e6c-98cc-125e2f494693",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Cria as variáveis de LOG\n",
    "format_log = '%Y-%m-%d %H:%M:%S'\n",
    "dtInicio = datetime.today() - timedelta(hours=3)\n",
    "dtInicio_format = dtInicio.strftime(format_log)\n",
    "tipo_log = 'API'\n",
    "camada = '<layer>'\n",
    "emissor = '<org>'\n",
    "atividade = '<activity_description>'\n",
    "origem = 'RestService'\n",
    "destino = 'AzureBlobFS'\n",
    "execUrl = ' '\n",
    "\n",
    "try:\n",
    "    infos = json.loads(dbutils.notebook.entry_point.getDbutils().notebook().getContext().toJson()) # captura as informações do job que executa o notebook\n",
    "    orgId = infos['tags']['orgId']\n",
    "    runId = infos['tags']['multitaskParentRunId']\n",
    "    jobId = infos['tags']['jobId']\n",
    "    if orgId == '2960871991268730': # Monta a URL caso seja o ID do ambiente de DEV\n",
    "        execUrl = f'https://adb-{orgId}.10.azuredatabricks.net/?o={orgId}#job/{jobId}/run/{runId}' # cria a url de execução do \n",
    "    else: # Monta a URL caso seja o ID do ambiente de PROD\n",
    "        execUrl = f'https://adb-{orgId}.15.azuredatabricks.net/?o={orgId}#job/{jobId}/run/{runId}' # cria a url de execução do \n",
    "except:\n",
    "    print('Campo de URL não pode ser identificado!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24508631-70e9-4b94-82d2-7a9be1262f92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "use catalog prod;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9186ab06-02d4-42b4-9897-08b2cd4ceec8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"dt_ingestao\", \"\")\n",
    "\n",
    "dt_ingestao = getArgument(\"dt_ingestao\").upper().strip()\n",
    "\n",
    "location_landing = spark.sql(\"show external locations\").select(\"url\").where(\"name = 'landing-area'\").collect()[0][0]\n",
    "\n",
    "print(location_landing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "faff256c-4e0b-4687-9b43-c8bfc437f256",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Formata o dt_ingestao\n",
    "format_timestamp = '%Y-%m-%d %H:%M:%S.%f'\n",
    "dt_ingestao = datetime.now() if dt_ingestao == \"\" else datetime.strptime(dt_ingestao, format_timestamp)\n",
    "\n",
    "# Pega o horário atual e tira 3 horas para converter para BRT (UTC -3)\n",
    "# Tira 5 minutos por conta de um limite da API\n",
    "dt_fim = dt_ingestao - timedelta(hours=3) - timedelta(minutes=5)\n",
    "dt_inicio = dt_fim - timedelta(days=1)\n",
    "\n",
    "# Força as horas, minutos e segundos em 0\n",
    "dt_inicio = datetime(dt_inicio.year, dt_inicio.month, dt_inicio.day, 0, 0, 0)\n",
    "\n",
    "# Separa as datas no formato UNIX\n",
    "dt_fim_unix = int(mktime(dt_fim.timetuple()))\n",
    "dt_inicio_unix = int(mktime(dt_inicio.timetuple()))\n",
    "\n",
    "# dt_inicio_unix = 1546300800\n",
    "\n",
    "# Transforma as datas em STRING utilizando um formato de timestamp\n",
    "dt_fim = dt_fim.strftime(format_timestamp)\n",
    "dt_inicio = dt_inicio.strftime(format_timestamp)\n",
    "\n",
    "print(f\"dt_inicio: {dt_inicio} | unix: {dt_inicio_unix}\")\n",
    "print(f\"dt_fim   : {dt_fim} | unix: {dt_fim_unix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdd1fe8b-eb8c-472b-91f9-ec6b1e008aa9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "domain = \"graph\"\n",
    "subdomain = \"facebook\"\n",
    "pageId = \"<page_id>\"\n",
    "threads = 10\n",
    "baseUrl = f\"https://{domain}.{subdomain}.com/v17.0/\"\n",
    "token = dbutils.secrets.get('scope-vault-data', 'facebook-pages-api-token')\n",
    "\n",
    "headers = {'Authorization': f'Bearer {token}'}\n",
    "\n",
    "print(baseUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68b986e6-d162-4cb1-8687-5c28a93f7488",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pega apenas cargas que possuem valor preenchido no campo \"ds_Url\" para não trazer tabelas que são geradas a partir de outro evento na landing.\n",
    "df_param = fn_ConsultaJdbc(\"\"\"\n",
    "    SELECT pca.*\n",
    "    FROM ctl.ADF_Parametro_Carga_API pca\n",
    "    WHERE pca.fl_ativo = 1\n",
    "    and nm_Sistema = 'facebook_pages'\n",
    "    and ds_Url is not null\n",
    "\"\"\")\n",
    "\n",
    "data_param = df_param.collect()\n",
    "\n",
    "display(df_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "018db539-cbc4-44b4-9348-1595f2511bc6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## SCRIPT PARA OBTER O PAGE_POST_ID e POST_VIDEO_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac79e513-2e80-4f35-bf18-6c794a5a2edd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "postId_set = set()\n",
    "postVideoId_set = set()\n",
    "\n",
    "urlPostId = f\"https://{domain}.{subdomain}.com/{pageId}/feed?fields=admin_creator,can_reply_privately,created_time,is_eligible_for_promotion,is_expired,feed_targeting,full_picture,is_hidden,icon,id,instagram_eligibility,message,parent_id,permalink_url,place,is_popular,privacy,promotable_id,is_published,is_spherical,status_type,story,story_tags,subscribed,targeting,updated_time,video_buying_eligibility\"\n",
    "\n",
    "while True:\n",
    "    req = requests.get(urlPostId, headers=headers)\n",
    "    data = req.json()\n",
    "    \n",
    "    for dados in data['data']:\n",
    "        postId_set.add(dados['id'])\n",
    "\n",
    "        if dados['status_type'] == 'added_video':\n",
    "            postVideoId_set.add(dados['id'])\n",
    "\n",
    "    if len(postId_set) == 150:\n",
    "        break\n",
    "    else:\n",
    "        urlPostId = data['paging']['next']\n",
    "\n",
    "print(\"Qtde POST_ID =\",len(postId_set))\n",
    "print(\"Qtde POST_VIDEO_ID =\",len(postVideoId_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "251948e2-a441-43c3-8711-da010342b301",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##SCRIPT DE INGESTÃO DE DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e421acb-0e99-4477-bb85-86f777fb0226",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_tables(param, baseUrl, dt_inicio_unix, dtIngestao, location_landing, headers):\n",
    "    end_point_page = None\n",
    "    try:\n",
    "        format_timestamp = '%Y-%m-%d %H:%M:%S.%f'\n",
    "        dtIngestao = str(dtIngestao)\n",
    "        if param.vl_Ultimo_Incremento is not None:\n",
    "            vlUltimoIncremento = datetime.strptime(param.vl_Ultimo_Incremento, format_timestamp)\n",
    "            vlUltimoIncremento = int(mktime(vlUltimoIncremento.timetuple()))\n",
    "        else:\n",
    "            vlUltimoIncremento = dt_inicio_unix\n",
    "\n",
    "        vlUltimoIncremento = str(vlUltimoIncremento)\n",
    "\n",
    "        # Landing\n",
    "        if param.vl_Schedule_Carga != 0:\n",
    "            dir_landing = f\"{location_landing}/{param.ds_Diretorio_Landing}/{param.ds_Nome_Arquivo_Landing}/{dtIngestao[0:4]}/{dtIngestao[5:7]}/{dtIngestao[8:10]}/{dtIngestao[11:13]}\".lower()\n",
    "        else:\n",
    "            dir_landing = f\"{location_landing}/{param.ds_Diretorio_Landing}/{param.ds_Nome_Arquivo_Landing}/{dtIngestao[0:4]}/{dtIngestao[5:7]}/{dtIngestao[8:10]}\".lower()\n",
    "        \n",
    "        start_date = \"1672531200\"\n",
    "        end_date = \"1677628800\"\n",
    "\n",
    "        # URL para o request\n",
    "        url = baseUrl + param.ds_Url\n",
    "\n",
    "        # Cria uma lista vazia para armazenar as respostas de cada request\n",
    "        result_data = []\n",
    "\n",
    "        # limite de registros por resposta da api (valor fixo)\n",
    "        # esse valor deve ser definido de acordo com a documentação da API\n",
    "        api_limit = 1000\n",
    "\n",
    "        # número máximo de erros permitodos antes de parar a execução (tentativas)\n",
    "        max_errors = 10\n",
    "\n",
    "        # tempo para esperar para tentar novamente em caso de erro (em segundos)\n",
    "        error_sleep = 30\n",
    "\n",
    "        if param.id_Parametro_Carga_API in (384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438):\n",
    "            url = baseUrl + param.ds_Url.replace('@START_DATE', vlUltimoIncremento).replace('@END_DATE', vlUltimoIncremento).replace('@PAGE_ID', pageId)\n",
    "            while True:\n",
    "                response = requests.get(url, headers=headers)\n",
    "                data = response.json()\n",
    "\n",
    "                for dados in data['data']:\n",
    "                    if 'id' in dados.keys():\n",
    "                        id_tratado = dados['id'].split('/')[0]\n",
    "                        dados['id'] = id_tratado\n",
    "            \n",
    "                    value_list = []\n",
    "                    for valores in dados['values']:\n",
    "                        if isinstance(valores['value'], dict):\n",
    "                            for category, valor in valores['value'].items():\n",
    "                                value_list.append({\"category\": category, \"value\":valor, \"end_time\":valores[\"end_time\"]})\n",
    "                                dados[\"values\"] = value_list\n",
    "\n",
    "                for dados in data['data']:\n",
    "                    result_data.append(dados)\n",
    "                \n",
    "                if 'next' in data['paging'].keys():\n",
    "                    url = data['paging']['next']\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        elif param.nm_Item_Origem in 'post':\n",
    "            url = baseUrl + param.ds_Url.replace('@START_DATE', vlUltimoIncremento).replace('@END_DATE', vlUltimoIncremento).replace('@PAGE_ID', pageId)\n",
    "\n",
    "            while True:\n",
    "                req = requests.get(url, headers=headers)\n",
    "                data = req.json()\n",
    "\n",
    "                for dados in data['data']:\n",
    "                    dados['page_id'] = '794115467360694'\n",
    "                    result_data.append(dados)\n",
    "\n",
    "                if 'paging' not in data.keys():\n",
    "                    break\n",
    "                else:\n",
    "                    if 'next' in data['paging'].keys():\n",
    "                        url = data['paging']['next']\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "        elif param.nm_Item_Origem in 'page':\n",
    "            url = baseUrl + param.ds_Url.replace('@START_DATE', vlUltimoIncremento).replace('@END_DATE', vlUltimoIncremento).replace('@PAGE_ID', pageId)\n",
    "            req = requests.get(url=url, headers=headers)\n",
    "            data = req.json()\n",
    "\n",
    "            for key, value in data.items():\n",
    "                if isinstance(value, list):\n",
    "                    for item in value:\n",
    "                        data[key] = item\n",
    "            result_data.append(data)\n",
    "\n",
    "        elif param.id_Parametro_Carga_API in (439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497):\n",
    "\n",
    "            for postId in postId_set:\n",
    "                url = baseUrl + param.ds_Url.replace('@START_DATE', vlUltimoIncremento).replace('@END_DATE', vlUltimoIncremento).replace('@PAGE_ID', pageId).replace('@PAGE_POST_ID', postId)\n",
    "                req = requests.get(url, headers=headers)\n",
    "\n",
    "                if req.status_code == 200:\n",
    "                    data = req.json()\n",
    "\n",
    "                    for dados in data['data']:\n",
    "                        if 'id' in dados.keys():\n",
    "                            id_tratado = dados['id'].split('/')[0]\n",
    "                            dados['id'] = id_tratado\n",
    "\n",
    "                        value_list = []\n",
    "                        for valores in dados['values']:\n",
    "                            if isinstance(valores['value'], dict):\n",
    "                                for category, valor in valores['value'].items():\n",
    "                                    value_list.append({\"category\": category, \"value\":valor})\n",
    "                                    dados[\"values\"] = value_list\n",
    "\n",
    "                    for dados in data['data']:\n",
    "                        result_data.append(dados)\n",
    "\n",
    "                else:\n",
    "                    print(f\"ERRO tabela {param.nm_Item_Origem}, URL: {url}\")\n",
    "\n",
    "        elif param.nm_Item_Origem in 'post_attachment':\n",
    "            for postId in postId_set:\n",
    "\n",
    "                url = baseUrl + param.ds_Url.replace('@PAGE_POST_ID', postId)\n",
    "\n",
    "                req = requests.get(url, headers=headers)\n",
    "                data = req.json()\n",
    "\n",
    "                for dados in data['data']:\n",
    "                    dados['page_post_id'] = f\"794115467360694_{dados['target']['id']}\"\n",
    "\n",
    "                for dados in data['data']:\n",
    "                    result_data.append(dados)\n",
    "                \n",
    "        elif param.nm_Item_Origem in 'post_tagged_object':\n",
    "            while True:\n",
    "                url = baseUrl + param.ds_Url.replace('@PAGE_ID', pageId)\n",
    "                req = requests.get(url, headers=headers)\n",
    "                data = req.json()\n",
    "\n",
    "                for dados in data['data']:\n",
    "                    result_data.append(dados)\n",
    "\n",
    "                if 'next' not in data.keys():\n",
    "                    break\n",
    "                else:\n",
    "                    url = data['next']\n",
    "\n",
    "        elif param.nm_Item_Origem in 'post_videos':\n",
    "            for postVideoId in postVideoId_set:\n",
    "                url = baseUrl + param.ds_Url.replace('@POST_VIDEO_ID', postVideoId)\n",
    "                req = requests.get(url, headers=headers)\n",
    "\n",
    "                if req.status_code == 200:\n",
    "                    data = req.json()\n",
    "                    result_data.append(data)\n",
    "\n",
    "                else:\n",
    "                    print(f\"ERRO tabela {param.nm_Item_Origem}, URL: {url}\")\n",
    "        \n",
    "        if len(result_data) == 0: # caso a quantidade de registros seja 0 (vazio), encerra a execução para evitar erros no LOG\n",
    "            return\n",
    "\n",
    "        fn_SaveJson(result_data, dir_landing, str(param.ds_Nome_Arquivo_Landing).lower())\n",
    "        fn_AtualizaUltimoIncremento_API(param.id_Parametro_Carga_API, dtIngestao)\n",
    "    \n",
    "        ## LOG SUCESSO\n",
    "        dtFim = datetime.today() - timedelta(hours=3)\n",
    "        dtFim_format = dtFim.strftime(format_log)\n",
    "        duracao = int((dtFim-dtInicio).total_seconds()) #captura a duração subtraindo o dtFim pelo dtInicio\n",
    "        dsParametro = str(param.asDict()) #captura todos os parâmetros\n",
    "        notebook = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "        \n",
    "        try:\n",
    "            pipeline = param.nm_Pipeline\n",
    "        except:\n",
    "            pipeline = os.path.basename(notebook)\n",
    "\n",
    "        if end_point_page is not None:\n",
    "            query = end_point_page\n",
    "        else:\n",
    "            query = ' '\n",
    "            \n",
    "        parametros = {\"tipo_log\": tipo_log,\"id_parametro\": param.id_Parametro_Carga_API, \"camada\": camada, \"dtInicio\": dtInicio_format, \"dtFim\": dtFim_format, \"pipeline\": pipeline, \"atividade\": atividade, \"notebook\": notebook, \"origem\": origem, \"destino\": destino, \"sistema\": param.nm_Sistema, \"emissor\": emissor, \"duracao\": duracao, \"query\": query, \"dsParametro\": dsParametro, \"execUrl\": execUrl}\n",
    "\n",
    "        fn_LogSucceeded(parametros, dt_ingestao.strftime(format_log))\n",
    "\n",
    "        return f\"Carga da tabela {param.ds_Nome_Arquivo_Landing} finalizada com sucesso.\"\n",
    "\n",
    "    except Exception as error:\n",
    "        ## LOG ERRO\n",
    "        dtFim = datetime.today() - timedelta(hours=3)\n",
    "        dtFim_format = dtFim.strftime(format_log)\n",
    "        duracao = int((dtFim-dtInicio).total_seconds()) #captura a duração subtraindo o dtFim pelo dtInicio\n",
    "        dsParametro = str(param.asDict()) #captura todos os parâmetros\n",
    "        notebook = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "        try:\n",
    "            pipeline = param.nm_Pipeline\n",
    "        except:\n",
    "            pipeline = os.path.basename(notebook)\n",
    "\n",
    "        if end_point_page is not None:\n",
    "            query = end_point_page\n",
    "        else:\n",
    "            query = ' '\n",
    "\n",
    "        if hasattr(error, 'code'): # captura o código do erro, caso possua o atributo 'code'\n",
    "            error_code = error.code\n",
    "        else:\n",
    "            error_code = 'NULL'\n",
    "            \n",
    "        parametros = {\"tipo_log\": tipo_log,\"id_parametro\": param.id_Parametro_Carga_API, \"camada\": camada, \"dtInicio\": dtInicio_format, \"dtFim\": dtFim_format, \"pipeline\": pipeline, \"atividade\": atividade, \"notebook\": notebook, \"origem\": origem, \"destino\": destino, \"sistema\": param.nm_Sistema, \"emissor\": emissor, \"duracao\": duracao, \"query\": query, \"dsParametro\": dsParametro, \"cd_erro\": error_code, \"erro\": str(error), \"execUrl\": execUrl}\n",
    "\n",
    "        fn_LogFailed(parametros, dt_ingestao.strftime(format_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b1e287a-f5ac-4392-b70e-03a112526e57",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cria uma lista para armazenar todas as tarefas\n",
    "tasks = []\n",
    "\n",
    "# Cria uma instância do ThreadPoolExecutor com threads definidas (max_workers)\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=threads) as executor:\n",
    "    # Percorre todas as pastas do diretório de origem\n",
    "    for row in data_param:\n",
    "        # Executa a função fn_StreamFromFolder_csv em uma thread do ThreadPoolExecutor\n",
    "        task = executor.submit(get_tables, *(row, baseUrl, dt_inicio_unix, dt_fim, location_landing, headers))\n",
    "                               \n",
    "        # Adiciona a tarefa à lista de tarefas\n",
    "        tasks.append(task)\n",
    "\n",
    "# Aguarda a conclusão de todas as tarefas\n",
    "_ = concurrent.futures.wait(tasks, return_when='ALL_COMPLETED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0be56682-a7c5-4db1-ab4d-430f3960252c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for task in tasks:\n",
    "    try:\n",
    "        print(task.result(),'\\n')\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "Process_Ingestao_VR_Gente_Facebook_Pages",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
