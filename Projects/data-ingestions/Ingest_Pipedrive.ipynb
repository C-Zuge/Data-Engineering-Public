{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b50f2fd-c754-4416-ba9a-7662aaafb3fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run Utils/Functions/core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fc637a4-7b34-4276-8789-fec965bb60f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import concurrent.futures\n",
    "import time\n",
    "from uuid import uuid4\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "from time import sleep, mktime\n",
    "import json\n",
    "from datetime import datetime, timedelta, timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8b4739f-7adb-4e11-9179-89f9b3c66253",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Cria as variáveis de LOG\n",
    "format_log = '%Y-%m-%d %H:%M:%S'\n",
    "dtInicio = datetime.today() - timedelta(hours=3)\n",
    "dtInicio_format = dtInicio.strftime(format_log)\n",
    "tipo_log = 'API'\n",
    "camada = 'landing'\n",
    "emissor = '<org>'\n",
    "atividade = 'activity_desc'\n",
    "origem = 'RestService'\n",
    "destino = 'AzureBlobFS'\n",
    "execUrl = ' '\n",
    "\n",
    "try:\n",
    "    infos = json.loads(dbutils.notebook.entry_point.getDbutils().notebook().getContext().toJson()) # captura as informações do job que executa o notebook\n",
    "    orgId = infos['tags']['orgId']\n",
    "    runId = infos['tags']['multitaskParentRunId']\n",
    "    jobId = infos['tags']['jobId']\n",
    "    if orgId == '2960871991268730': # Monta a URL caso seja o ID do ambiente de DEV\n",
    "        execUrl = f'https://adb-{orgId}.10.azuredatabricks.net/?o={orgId}#job/{jobId}/run/{runId}' # cria a url de execução do \n",
    "    else: # Monta a URL caso seja o ID do ambiente de PROD\n",
    "        execUrl = f'https://adb-{orgId}.15.azuredatabricks.net/?o={orgId}#job/{jobId}/run/{runId}' # cria a url de execução do \n",
    "except:\n",
    "    print('Campo de URL não pode ser identificado!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97313f5c-251a-4dc9-835d-0cf195d85c05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"dt_ingestao\", \"\")\n",
    "\n",
    "dt_ingestao = getArgument(\"dt_ingestao\").upper().strip()\n",
    "\n",
    "location_landing = spark.sql(\"show external locations\").select(\"url\").where(\"name = 'landing-area'\").collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d8012c5-bb73-4277-bd98-0d63d3ed988e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Formata o dt_ingestao\n",
    "format_timestamp = '%Y-%m-%d %H:%M:%S.%f'\n",
    "format_timestamp_api = '%Y-%m-%d'\n",
    "dt_ingestao = datetime.now() if dt_ingestao == \"\" else datetime.strptime(dt_ingestao, format_timestamp)\n",
    "\n",
    "# Pega o horário atual e tira 3 horas para converter para BRT (UTC -3)\n",
    "# Tira 5 minutos por conta de um limite da API\n",
    "dt_fim = dt_ingestao - timedelta(hours=3) - timedelta(minutes=5)\n",
    "dt_inicio = dt_fim - timedelta(days=1)\n",
    "\n",
    "dt_inicio_api_format = dt_ingestao - timedelta(days=5)\n",
    "dt_fim_api_format = dt_ingestao\n",
    "dt_inicio_api = dt_inicio_api_format.strftime(format_timestamp_api)\n",
    "dt_fim_api = dt_fim_api_format.strftime(format_timestamp_api)\n",
    "\n",
    "# Força as horas, minutos e segundos em 0\n",
    "dt_inicio = datetime(dt_inicio.year, dt_inicio.month, dt_inicio.day, 0, 0, 0)\n",
    "\n",
    "# Separa as datas no formato UNIX\n",
    "dt_fim_unix = int(mktime(dt_fim.timetuple()))\n",
    "dt_inicio_unix = int(mktime(dt_inicio.timetuple()))\n",
    "\n",
    "# dt_inicio_unix = 1546300800\n",
    "\n",
    "# Transforma as datas em STRING utilizando um formato de timestamp\n",
    "dt_fim = dt_fim.strftime(format_timestamp)\n",
    "dt_inicio = dt_inicio.strftime(format_timestamp)\n",
    "\n",
    "print(f\"Data ínicio do filtro API: {dt_inicio_api} | Data fim do filtro API: {dt_fim_api}\")\n",
    "print(f\"dt_inicio: {dt_inicio} | unix: {dt_inicio_unix}\")\n",
    "print(f\"dt_fim   : {dt_fim} | unix: {dt_fim_unix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "904bfd8b-7576-4af7-b214-b83ba853b1c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "api_token = dbutils.secrets.get(\"scope-vault-data\", \"pipedrive-api-token\")\n",
    "domain = 'api.pipedrive.com/v1'\n",
    "params = {'api_token': f'{api_token}'}\n",
    "threads = 10\n",
    "baseUrl = f\"https://{domain}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9f80916-ad6c-4f5b-acf5-df6323a237b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_param = fn_ConsultaJdbc(\"\"\"\n",
    "    SELECT *\n",
    "    FROM ctl.ADF_Parametro_Carga_API pca\n",
    "    WHERE pca.fl_ativo = 1\n",
    "    and nm_Sistema = 'pipedrive'\n",
    "\"\"\")\n",
    "\n",
    "display(df_param)\n",
    "data_param = df_param.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd9c0275-7ed8-4935-ade6-e36b7e352a2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_tables(param, baseUrl, dt_inicio_unix, dtIngestao, location_landing):\n",
    "    end_point_page = None\n",
    "    try:\n",
    "        format_timestamp = '%Y-%m-%d %H:%M:%S.%f'\n",
    "        dtIngestao = str(dtIngestao)\n",
    "        if param.vl_Ultimo_Incremento is not None:\n",
    "            vlUltimoIncremento = datetime.strptime(param.vl_Ultimo_Incremento, format_timestamp)\n",
    "            vlUltimoIncremento = int(mktime(vlUltimoIncremento.timetuple()))\n",
    "        else:\n",
    "            vlUltimoIncremento = dt_inicio_unix\n",
    "\n",
    "        vlUltimoIncremento = str(vlUltimoIncremento)\n",
    "\n",
    "        # Declarando as variáveis\n",
    "        pagina = 1\n",
    "        cursor = None\n",
    "        paginacao = False\n",
    "        inicio = time.time()\n",
    "\n",
    "        if param.vl_Schedule_Carga != 0:\n",
    "            dir_landing = f\"{location_landing}/{param.ds_Diretorio_Landing}/{param.ds_Nome_Arquivo_Landing}/{dtIngestao[0:4]}/{dtIngestao[5:7]}/{dtIngestao[8:10]}/{dtIngestao[11:13]}\".lower()\n",
    "            alter_landing = f\"{location_landing}/{param.ds_Diretorio_Landing}/@alter_table/{dtIngestao[0:4]}/{dtIngestao[5:7]}/{dtIngestao[8:10]}/{dtIngestao[11:13]}\".lower()\n",
    "        else:\n",
    "            dir_landing = f\"{location_landing}/{param.ds_Diretorio_Landing}/{param.ds_Nome_Arquivo_Landing}/{dtIngestao[0:4]}/{dtIngestao[5:7]}/{dtIngestao[8:10]}\".lower()\n",
    "            alter_landing = f\"{location_landing}/{param.ds_Diretorio_Landing}/@alter_table/{dtIngestao[0:4]}/{dtIngestao[5:7]}/{dtIngestao[8:10]}\".lower()\n",
    "\n",
    "        print(f\"Tabela {param.nm_Item_Origem}! Começando carga...\")\n",
    "\n",
    "        data_list = []\n",
    "\n",
    "        # Pega o endpoint que utilizará no request\n",
    "        # Verificação para casos especiais que salvam a última URL que processou\n",
    "        # Faz um replace passando a página 0 para a primeira requisição, no caso da tabela activities utiliza o cursor que, para a primeira requisição, não é utilizado!\n",
    "        if param.ds_Custom_Field is None:\n",
    "            end_point_page = f\"{baseUrl}{param.ds_Url.replace('@pagina', '0').replace('@dtInicio','').replace('@dtFim','')}\"\n",
    "        else:\n",
    "            end_point_page = param.ds_Custom_Field\n",
    "            if param.nm_Item_Origem == 'activities':\n",
    "                end_point_page = end_point_page.replace('@dtInicio',dt_inicio_api).replace('@dtFim',dt_fim_api).replace('@pagina','0')      \n",
    "\n",
    "        # Envia a primeira requisição\n",
    "        req = requests.get(end_point_page,params=params)\n",
    "        last_endpoint = end_point_page\n",
    "\n",
    "        # Verifica se a primeira requisição teve erro\n",
    "        if req.status_code != 200:\n",
    "            print(\"\\n\"+f\"Tabela {param.nm_Item_Origem} com erro na primeira requisição!\")\n",
    "        # Caso a response da requisição seja 200 (sucesso) \n",
    "        else:\n",
    "            # Armazena o conteúdo da API na variável data em formato JSON\n",
    "            data = req.json()\n",
    "\n",
    "            data_keys = list(data.keys())\n",
    "\n",
    "            if 'data' in data_keys:\n",
    "                if data['data'] == None:\n",
    "                    return\n",
    "\n",
    "            if 'additional_data' in data_keys:\n",
    "                if 'next_cursor' in list(data['additional_data'].keys()):\n",
    "                    if data['additional_data']['next_cursor'] != None:\n",
    "                        cursor = data['additional_data']['next_cursor']\n",
    "                        try:\n",
    "                            end_point_page = f\"{baseUrl}{param.ds_Url.replace('@cursor', cursor)}\"\n",
    "                        except:\n",
    "                            raise Exception(f'Não foi possível encontrar a próxima página para a tabela --> {param.ds_Nome_Arquivo_Landing}\\nPágina --> {pagina}')\n",
    "                elif 'pagination' in list(data['additional_data'].keys()):\n",
    "                    if 'more_items_in_collection' in list(data['additional_data']['pagination'].keys()):\n",
    "                        if data['additional_data']['pagination']['more_items_in_collection'] == True:\n",
    "                            paginacao = data['additional_data']['pagination']['more_items_in_collection']\n",
    "                            param_start = str(data['additional_data']['pagination']['next_start'])\n",
    "                            try:\n",
    "                                end_point_page = f\"{baseUrl}{param.ds_Url.replace('@pagina', param_start)}\"\n",
    "                                if param.nm_Item_Origem == 'activities':\n",
    "                                    if param.ds_Custom_Field is not None:\n",
    "                                        end_point_page = param.ds_Custom_Field.replace('@dtInicio',dt_inicio_api).replace('@dtFim',dt_fim_api).replace('@pagina',param_start)\n",
    "                                    else:\n",
    "                                        end_point_page = f\"{baseUrl}{param.ds_Url.replace('@dtInicio','').replace('@dtFim','').replace('@pagina',param_start)}\"\n",
    "                            except:\n",
    "                                raise Exception(f'Não foi possível encontrar a próxima página para a tabela --> {param.ds_Nome_Arquivo_Landing}\\nPágina --> {pagina}')\n",
    "\n",
    "            # Salva os dados na lista\n",
    "            if param.nm_Item_Origem == 'goals':\n",
    "                data_list.extend(data['data']['goals'])\n",
    "            else:\n",
    "                data_list.extend(data['data'])\n",
    "\n",
    "            if len(data_list) == 0: # caso a quantidade de registros seja 0 (vazio), encerra a execução para evitar erros no LOG\n",
    "                return\n",
    "\n",
    "        # Faz requisições até que o campo \"next-page\" da API venha com valor Null, significa que todas as páginas foram percorridas\n",
    "        while paginacao == True or cursor != None:\n",
    "            cursor = None\n",
    "            paginacao = False\n",
    "            pagina += 1\n",
    "\n",
    "            # Envia a requisição para a página seguinte\n",
    "            req = requests.get(end_point_page,params=params)\n",
    "            last_endpoint = end_point_page\n",
    "\n",
    "            # Em caso de erro entra no laço\n",
    "            if req.status_code != 200:\n",
    "                print(\"\\n\"+f\"Tabela {param.nm_Item_Origem} com erro na requisição da página {pagina}\")\n",
    "            else:\n",
    "                data = req.json()\n",
    "\n",
    "                data_keys = list(data.keys())\n",
    "\n",
    "                if 'data' in data_keys:\n",
    "                    if data['data'] == None:\n",
    "                        break\n",
    "\n",
    "                if 'additional_data' in data_keys:\n",
    "                    if 'next_cursor' in list(data['additional_data'].keys()):\n",
    "                        if data['additional_data']['next_cursor'] != None:\n",
    "                            cursor = data['additional_data']['next_cursor']\n",
    "                            try:\n",
    "                                end_point_page = f\"{baseUrl}{param.ds_Url.replace('@cursor', cursor)}\"\n",
    "                            except:\n",
    "                                raise Exception(f'Não foi possível encontrar a próxima página para a tabela --> {param.ds_Nome_Arquivo_Landing}\\nPágina --> {pagina}')\n",
    "                    elif 'pagination' in list(data['additional_data'].keys()):\n",
    "                        if 'more_items_in_collection' in list(data['additional_data']['pagination'].keys()):\n",
    "                            if data['additional_data']['pagination']['more_items_in_collection'] == True:\n",
    "                                paginacao = data['additional_data']['pagination']['more_items_in_collection']\n",
    "                                param_start = str(data['additional_data']['pagination']['next_start'])\n",
    "                                try:\n",
    "                                    end_point_page = f\"{baseUrl}{param.ds_Url.replace('@pagina', param_start)}\"\n",
    "                                    if param.nm_Item_Origem == 'activities':\n",
    "                                        if param.ds_Custom_Field is not None:\n",
    "                                            end_point_page = param.ds_Custom_Field.replace('@dtInicio',dt_inicio_api).replace('@dtFim',dt_fim_api).replace('@pagina',param_start)\n",
    "                                        else:\n",
    "                                            end_point_page = f\"{baseUrl}{param.ds_Url.replace('@dtInicio','').replace('@dtFim','').replace('@pagina',param_start)}\"\n",
    "                                except:\n",
    "                                    raise Exception(f'Não foi possível encontrar a próxima página para a tabela --> {param.ds_Nome_Arquivo_Landing}\\nPágina --> {pagina}')\n",
    "                \n",
    "                if param.nm_Item_Origem == 'goals':\n",
    "                    data_list.extend(data['data']['goals'])\n",
    "                else:\n",
    "                    data_list.extend(data['data'])\n",
    "\n",
    "        fim = time.time()\n",
    "\n",
    "        if param.ds_Custom_Field is not None and param.nm_Item_Origem != 'activities':\n",
    "            fn_AtualizaCustomField_API(param.id_Parametro_Carga_API, last_endpoint)\n",
    "        \n",
    "        # Subtrai a variável \"início\" pela \"fim\" para obter o tempo total de execução da tabela e armazena na váriavel \"tempo_exec\"\n",
    "        tempo_exec = fim - inicio\n",
    "\n",
    "        print(\"\\n\"+f\"A tabela {param.nm_Item_Origem} teve {pagina} páginas carregadas com êxito!\")\n",
    "        print(f\"Tamanho total de registros {len(data_list)}\")\n",
    "        print(f\"O tempo de execução da tabela {param.nm_Item_Origem} foi {tempo_exec}\")\n",
    "\n",
    "        # PROCESSO DE CARGA DOS DADOS NO BLOB\n",
    "        fn_SaveJson(data_list, dir_landing, str(param.ds_Nome_Arquivo_Landing).lower())\n",
    "\n",
    "        fn_AtualizaUltimoIncremento_API(param.id_Parametro_Carga_API, dtIngestao)\n",
    "\n",
    "        ## LOG SUCESSO\n",
    "        dtFim = datetime.today() - timedelta(hours=3)\n",
    "        dtFim_format = dtFim.strftime(format_log)\n",
    "        duracao = int((dtFim-dtInicio).total_seconds()) #captura a duração subtraindo o dtFim pelo dtInicio\n",
    "        dsParametro = str(param.asDict()) #captura todos os parâmetros\n",
    "        notebook = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "        \n",
    "        try:\n",
    "            pipeline = param.nm_Pipeline\n",
    "        except:\n",
    "            pipeline = os.path.basename(notebook)\n",
    "\n",
    "        if end_point_page is not None:\n",
    "            query = end_point_page\n",
    "        else:\n",
    "            query = ' '\n",
    "            \n",
    "        parametros = {\"tipo_log\": tipo_log,\"id_parametro\": param.id_Parametro_Carga_API, \"camada\": camada, \"dtInicio\": dtInicio_format, \"dtFim\": dtFim_format, \"pipeline\": pipeline, \"atividade\": atividade, \"notebook\": notebook, \"origem\": origem, \"destino\": destino, \"sistema\": param.nm_Sistema, \"emissor\": emissor, \"duracao\": duracao, \"query\": query, \"dsParametro\": dsParametro, \"execUrl\": execUrl}\n",
    "\n",
    "        fn_LogSucceeded(parametros, dt_ingestao.strftime(format_log))\n",
    "\n",
    "    except Exception as error:\n",
    "        ## LOG ERRO\n",
    "        dtFim = datetime.today() - timedelta(hours=3)\n",
    "        dtFim_format = dtFim.strftime(format_log)\n",
    "        duracao = int((dtFim-dtInicio).total_seconds()) #captura a duração subtraindo o dtFim pelo dtInicio\n",
    "        dsParametro = str(param.asDict()) #captura todos os parâmetros\n",
    "        notebook = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "        try:\n",
    "            pipeline = param.nm_Pipeline\n",
    "        except:\n",
    "            pipeline = os.path.basename(notebook)\n",
    "\n",
    "        if end_point_page is not None:\n",
    "            query = end_point_page\n",
    "        else:\n",
    "            query = ' '\n",
    "\n",
    "        if hasattr(error, 'code'): # captura o código do erro, caso possua o atributo 'code'\n",
    "            error_code = error.code\n",
    "        else:\n",
    "            error_code = 'NULL'\n",
    "            \n",
    "        parametros = {\"tipo_log\": tipo_log,\"id_parametro\": param.id_Parametro_Carga_API, \"camada\": camada, \"dtInicio\": dtInicio_format, \"dtFim\": dtFim_format, \"pipeline\": pipeline, \"atividade\": atividade, \"notebook\": notebook, \"origem\": origem, \"destino\": destino, \"sistema\": param.nm_Sistema, \"emissor\": emissor, \"duracao\": duracao, \"query\": query, \"dsParametro\": dsParametro, \"cd_erro\": error_code, \"erro\": str(error), \"execUrl\": execUrl}\n",
    "\n",
    "        fn_LogFailed(parametros, dt_ingestao.strftime(format_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6bb12bd-9497-452b-a25d-3b1cb65532fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cria uma lista para armazenar todas as tarefas\n",
    "tasks = []\n",
    "\n",
    "# Cria uma instância do ThreadPoolExecutor com threads definidas (max_workers)\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=threads) as executor:\n",
    "    # Percorre todas as pastas do diretório de origem\n",
    "    for row in data_param:\n",
    "        # Executa a função fn_StreamFromFolder_csv em uma thread do ThreadPoolExecutor\n",
    "        task = executor.submit(get_tables, *(row, baseUrl, dt_inicio_unix, dt_fim, location_landing))\n",
    "                               \n",
    "        # Adiciona a tarefa à lista de tarefas\n",
    "        tasks.append(task)\n",
    "\n",
    "# Aguarda a conclusão de todas as tarefas\n",
    "_ = concurrent.futures.wait(tasks, return_when='ALL_COMPLETED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23804be2-17c0-4aad-a96d-4fb2ac60ee2b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for task in tasks:\n",
    "    try:\n",
    "        print(task.result(),'\\n')\n",
    "    except Exception as error:\n",
    "        print(error)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "Process_Ingestao_VR_Gente_Pipedrive",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
